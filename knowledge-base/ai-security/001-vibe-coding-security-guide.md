# Vibe Coding 安全手冊：保護你的資產，避免被 AI 轉走

> **來源**: [@YukerX](https://x.com/YukerX/status/2010979912535195750) | [原文連結](https://x.com/i/article/2010645662577184768)
>
> **日期**: 
>
> **標籤**: `Vibe Coding` `AI安全` `提示注入` `沙箱` `權限管理`

---

以下是根據提供的資料整理出的知識庫文章，目標是提供一個關於 Vibe Coding 安全使用的指南。

## Vibe Coding 安全手冊：保護你的資產，避免被 AI 轉走

### 總覽

本文旨在提供 Vibe Coding 的安全使用指南，協助使用者像管理一位才華橫溢但不可完全信任的「天才實習生」一樣管理 AI。透過沙箱、權限系統和建立審查習慣，有效防範提示注入等安全風險，最終保護個人資產安全。

### 核心心法：像管理「天才實習生」一樣管理 AI

Backslash Security 的經典名言：將 Vibe Coding 視為一個才華橫溢但不可完全信任的實習生。它可以做出令人驚豔的工作，但你必須監督它，並在投入生產之前仔細檢查一切。

作為導師，你的職責是：
*   設定清晰的邊界
*   審查每一次關鍵操作

### 安全三劍客：認識你的安全基石

Vibe Coding 的安全體系建立在三個核心概念之上，它們是：

1.  **權限系統 (Permission System) - 門禁卡**：決定你的 AI 助手在什麼情況下可以做什麼事。核心指令：Allow (允許)、Ask (詢問)、Deny (拒絕)。
2.  **沙箱 (Sandbox) - 「防爆實驗室」**：一個隔離的執行環境，將 Claude Code 和你的電腦系統隔離開。
3.  **提示注入（Prompt Injection）**：一種常見的攻擊技術，攻擊者在你分析的程式碼、文檔或網頁中，偷偷藏入給 Claude Code 的惡意指令。

### 新手快速入門：三步建立你的安全底線（SOP）

1.  **步驟一：開啟沙箱**

    *   在 Vibe Coding 的對話框中輸入 `/sandbox` 並回車。（目前沙箱功能主要在 macOS 和 Linux 系統上提供支援。）
    *   沙箱設置選項：
        *   **Auto - Allow**：信任 Claude 且追求效率。
        *   **Regular Permissions**：注重細節或處理關鍵程式碼。
        *   **Override 選項**：
            *   **Allow unsandboxed fallback**：允許在沙箱遇到網路或權限問題時，嘗試使用 `dangerouslyDisableSandbox` 參數重新執行，並觸發正常的權限詢問流程。
            *   **Strict sandbox mode**：完全關閉逃生門。如果命令在沙箱裡跑不通，則直接失敗。

2.  **步驟二：配置「拒絕清單」**

    1.  找到 Claude Code 的設定檔（通常在主目錄的 `Settings` 或 `Settings.local` 檔案中）。
    2.  配置 `Permissions` 規則：

    ```json
    {
      "permissions": {
        "deny": [
          "Read(./.env*)",
          "Read(~/.ssh/**)",
          "Read(~/.aws/**)",
          "Read(~/.kube/**)",
          "Read(~/.gitconfig)"
        ]
      }
    }
    ```

    *   `deny` 表示強制禁止執行，`Read` 表示讀取權限。
    *   若想適度放寬權限，可將規則放入 `Ask` 裡面，以兼顧安全與彈性。
    *   路徑格式：對於全局性的 `deny` 規則，使用 `~/` 或 `//`，確保在任何專案、任何路徑下都生效。

3.  **步驟三：養成「審查習慣」**

    當 Vibe Coding 申請執行命令或修改檔案時，花 3 秒鐘問自己三個問題：

    *   它想做什麼？
    *   這個操作符合我目前的意圖嗎？
    *   這個操作有潛在風險嗎？

### 真實模擬攻擊：一次「提示注入」的完整復盤

以小明下載惡意 Skill 為例：

1.  **偽裝 (The Lure)**：攻擊者提供誘人的 Skill。
2.  **觸發 (The Trigger)**：小明要求 Claude Code 使用該 Skill 整理專案文檔。
3.  **執行 (The Execution)**：Claude 讀取 Skill 指令，執行 `curl` 命令。
4.  **致命一擊 (The Payload)**：腳本掃描並發送 `.ssh/id_rsa` 到黑客伺服器。

**防禦拆解：**

1.  **防禦層 1 - 審查習慣**：拒絕執行包含 `curl` 和陌生網址的命令。
2.  **防禦層 2 - 沙箱網路隔離**：阻止 `curl` 訪問未授權的域名。
3.  **防禦層 3 - 權限規則**：明確禁止 `curl` 命令。

    ```json
    "deny": ["Bash(curl*)"]
    ```

### 安全是一種習慣，而非一組配置

最强大的安全工具，是你自己的大脑。對 AI 生成的每一行程式碼、每一個 AI 請求的命令都保持著健康的懷疑。

**最終建議：**

從複製範本開始，但更重要的是，理解每一條規則背後的「為什麼」。當你能獨立地為你的下一個專案寫出自己的安全配置時，你就真正地從「實習生導師」，成長為了一位能夠駕馭 Claude Code 等 AI 工具的大師。

### 重點表：安全檢查清單

| 安全措施      | 說明                                                                                     | 實施方法                                                                                                  |
| ----------- | ---------------------------------------------------------------------------------------- | ------------------------------------------------------------------------------------------------------- |
| 啟用沙箱      | 隔離 AI 的執行環境，防止其影響電腦系統。                                                                   | 在 Vibe Coding 對話框中輸入 `/sandbox` 並回車。                                                                   |
| 配置拒絕清單    | 主動禁止 AI 訪問敏感檔案和目錄。                                                                           | 編輯 Claude Code 的設定檔，在 `permissions.deny` 中加入相應規則。                                                         |
| 養成審查習慣    | 對 AI 執行的命令和修改的檔案進行審查，判斷其意圖和潛在風險。                                                                | 每次 AI 請求執行操作時，花 3 秒鐘思考：它想做什麼？這個操作符合我的意圖嗎？這個操作有潛在風險嗎？                                                  |
| 警惕提示注入攻擊 | 避免使用來路不明的程式碼或 Skill，並對程式碼中包含的命令保持警惕。                                                               | 檢查 Skill 的程式碼，特別是包含 `curl`、`bash` 等命令的部分，避免執行未經授權的網路請求或執行惡意腳本。                                            |
| 定期更新安全配置 | 隨著 AI 技術的發展，新的安全風險也會不斷出現，定期檢查和更新安全配置，確保防護措施的有效性。                                                      | 關注安全社群的最新資訊，了解最新的安全風險和防護方法，並根據實際情況調整安全配置。                                                             |
| 保持懷疑態度    | 不要盲目信任 AI，對 AI 生成的程式碼和建議保持警惕，並進行人工審查，確保其安全性和正確性。                                                        | 對 AI 產生的內容進行批判性思考，並結合自己的知識和經驗進行判斷。                                                                 |


